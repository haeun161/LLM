{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDyGS6ulcD_L",
        "outputId": "6196317e-1dc3-4ff2-ff08-571bfbcc04ad"
      },
      "outputs": [],
      "source": [
        "%pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VGn02HwOcn_Z"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lID-96rRcwpx"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQQAEdaky2SK"
      },
      "source": [
        "# Hello World"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LQwwroebdYJl"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"write a haiku about ai\"}\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh1y9q1jdptt",
        "outputId": "3871944e-cbb5-4860-8720-d2c00b4c5278"
      },
      "outputs": [],
      "source": [
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMcPuy3pytUK",
        "outputId": "bb6d66ef-bcba-4199-a788-cbe3ca38c777"
      },
      "outputs": [],
      "source": [
        "completion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWGMiqVnyyL_"
      },
      "source": [
        "# Capabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRJVeYFk1Gkr"
      },
      "source": [
        "## 텍스트 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KFiEyHntyz8q"
      },
      "outputs": [],
      "source": [
        "# from openai import OpenAI\n",
        "# client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is a LLM?\"}\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVyXoDXfzJKe",
        "outputId": "dbc2c24e-ea29-48e3-a88a-78893e7ceb20"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ1S1uzzzTA7",
        "outputId": "e081980b-2a95-4281-de1b-83abb3d46367"
      },
      "outputs": [],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBkw-OqA1Ef3"
      },
      "source": [
        "## 비전"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh3aAuC91J0F",
        "outputId": "68312d2f-4873-45c4-d119-8273016c978d"
      },
      "outputs": [],
      "source": [
        "# from openai import OpenAI\n",
        "\n",
        "# client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "        {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
        "        {\n",
        "          \"type\": \"image_url\",\n",
        "          \"image_url\": {\n",
        "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
        "          },\n",
        "        },\n",
        "      ],\n",
        "    }\n",
        "  ],\n",
        "  max_tokens=300,\n",
        ")\n",
        "\n",
        "print(response.choices[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQtUAsve1sSp",
        "outputId": "039c223a-baf7-46bb-ef45-b1abe1bec393"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBN13HZ31UmN",
        "outputId": "2d207cff-e682-476a-c9b2-488d34aa9c71"
      },
      "outputs": [],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKDaVOP-BpYO"
      },
      "source": [
        "## 구조화된 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "383G66DX97Xt"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "from openai import OpenAI\n",
        "\n",
        "# client = OpenAI()\n",
        "\n",
        "class Step(BaseModel):\n",
        "    explanation: str\n",
        "    output: str\n",
        "\n",
        "class MathReasoning(BaseModel):\n",
        "    steps: list[Step]\n",
        "    final_answer: str\n",
        "\n",
        "completion = client.beta.chat.completions.parse(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful math tutor. Guide the user through the solution step by step.\"},\n",
        "        {\"role\": \"user\", \"content\": \"how can I solve 8x + 7 = -23\"}\n",
        "    ],\n",
        "    response_format=MathReasoning,\n",
        ")\n",
        "\n",
        "math_reasoning = completion.choices[0].message.parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ba__RUM3-DAs",
        "outputId": "7dd8e33b-54ef-4042-bfd6-217c04c3519d"
      },
      "outputs": [],
      "source": [
        "math_reasoning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxdL4Jk1BudB"
      },
      "source": [
        "# Introduction to gpt4o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMBD_ACvprF8"
      },
      "source": [
        "https://github.com/openai/openai-cookbook/tree/main/examples/gpt4o 에서 data 폴더의 내용 업로드 후 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Sv2036alBxzB"
      },
      "outputs": [],
      "source": [
        "MODEL=\"gpt-4o-mini\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJDGkK_VB2ma",
        "outputId": "1e8a8b19-9041-47fa-dfed-3b40fd6c2aa7"
      },
      "outputs": [],
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=MODEL,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Help me with my math homework!\"}, # <-- This is the system message that provides context to the model\n",
        "    {\"role\": \"user\", \"content\": \"Hello! Could you solve 2+2?\"}  # <-- This is the user message for which the model will generate a response\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(\"Assistant: \" + completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ4BkhqAB6-g"
      },
      "source": [
        "## Image Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "rsT4oLJTB9CP",
        "outputId": "54ad83e6-2a21-418e-9a65-1309664fdab9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display, Audio, Markdown\n",
        "import base64\n",
        "\n",
        "IMAGE_PATH = \"./triangle.png\"\n",
        "\n",
        "# Preview image for context\n",
        "display(Image(IMAGE_PATH))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF2DmaknClLX"
      },
      "source": [
        "### Base64 Image Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK5OKSFnCjPa",
        "outputId": "762c789d-1252-4e35-d30f-c6c2299de478"
      },
      "outputs": [],
      "source": [
        "# Open the image file and encode it as a base64 string\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "base64_image = encode_image(IMAGE_PATH)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that responds in Markdown. Help me with my math homework!\"},\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"text\", \"text\": \"What's the area of the triangle?\"},\n",
        "            {\"type\": \"image_url\", \"image_url\": {\n",
        "                \"url\": f\"data:image/png;base64,{base64_image}\"}\n",
        "            }\n",
        "        ]}\n",
        "    ],\n",
        "    temperature=0.0,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeLbgZoRDKU7"
      },
      "source": [
        "### URL Image Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cneuBxqZCxGu",
        "outputId": "f4c94c43-b231-4f32-a94a-a1be321d6d2e"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that responds in Markdown. Help me with my math homework!\"},\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"text\", \"text\": \"What's the area of the triangle?\"},\n",
        "            {\"type\": \"image_url\", \"image_url\": {\n",
        "                \"url\": \"https://upload.wikimedia.org/wikipedia/commons/e/e2/The_Algebra_of_Mohammed_Ben_Musa_-_page_82b.png\"}\n",
        "            }\n",
        "        ]}\n",
        "    ],\n",
        "    temperature=0.0,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnoW_h8JU1U5"
      },
      "source": [
        "## Video Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2tjHciLDOZO",
        "outputId": "11423588-9f90-4b42-8a9a-f90342948d5c"
      },
      "outputs": [],
      "source": [
        "!sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWasGPXgU68t",
        "outputId": "3baadd04-14a9-4cc3-bc1d-0c075d247198"
      },
      "outputs": [],
      "source": [
        "%pip install opencv-python\n",
        "%pip install moviepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-552UCuqVo1V"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from moviepy.editor import VideoFileClip\n",
        "import time\n",
        "import base64\n",
        "\n",
        "# We'll be using the OpenAI DevDay Keynote Recap video. You can review the video here: https://www.youtube.com/watch?v=h02ti0Bl6zk\n",
        "VIDEO_PATH = \"keynote_recap.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSjVE2ELV14y",
        "outputId": "4191696a-4d3e-4379-87f6-eadf0e5aaaba"
      },
      "outputs": [],
      "source": [
        "def process_video(video_path, seconds_per_frame=2):\n",
        "    base64Frames = []\n",
        "    base_video_path, _ = os.path.splitext(video_path)\n",
        "\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "    frames_to_skip = int(fps * seconds_per_frame)\n",
        "    curr_frame=0\n",
        "\n",
        "    # Loop through the video and extract frames at specified sampling rate\n",
        "    while curr_frame < total_frames - 1:\n",
        "        video.set(cv2.CAP_PROP_POS_FRAMES, curr_frame)\n",
        "        success, frame = video.read()\n",
        "        if not success:\n",
        "            break\n",
        "        _, buffer = cv2.imencode(\".jpg\", frame)\n",
        "        base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
        "        curr_frame += frames_to_skip\n",
        "    video.release()\n",
        "\n",
        "    # Extract audio from video\n",
        "    audio_path = f\"{base_video_path}.mp3\"\n",
        "    clip = VideoFileClip(video_path)\n",
        "    clip.audio.write_audiofile(audio_path, bitrate=\"32k\")\n",
        "    clip.audio.close()\n",
        "    clip.close()\n",
        "\n",
        "    print(f\"Extracted {len(base64Frames)} frames\")\n",
        "    print(f\"Extracted audio to {audio_path}\")\n",
        "    return base64Frames, audio_path\n",
        "\n",
        "# Extract 1 frame per second. You can adjust the `seconds_per_frame` parameter to change the sampling rate\n",
        "base64Frames, audio_path = process_video(VIDEO_PATH, seconds_per_frame=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "4qHwXuDCV_Ll",
        "outputId": "2b8056a5-c28c-4fb4-c7e2-d7d3bc31c63f"
      },
      "outputs": [],
      "source": [
        "## Display the frames and audio for context\n",
        "display_handle = display(None, display_id=True)\n",
        "for img in base64Frames:\n",
        "    display_handle.update(Image(data=base64.b64decode(img.encode(\"utf-8\")), width=600))\n",
        "    time.sleep(0.025)\n",
        "\n",
        "Audio(audio_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9fbUejqW9l6"
      },
      "source": [
        "## Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7XYQHvlXGQa"
      },
      "source": [
        "Visual Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH-tejRNXBQ7",
        "outputId": "f56c26ab-2a7c-43e5-dac5-968734c1e174"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are generating a video summary. Please provide a summary of the video. Respond in Markdown.\"},\n",
        "    {\"role\": \"user\", \"content\": [\n",
        "        \"These are the frames from the video.\",\n",
        "        *map(lambda x: {\"type\": \"image_url\",\n",
        "                        \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, base64Frames)\n",
        "        ],\n",
        "    }\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYcRS6wQXK68"
      },
      "source": [
        "Audio Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTVydmu0XL-u",
        "outputId": "721a466c-fbc3-45b0-9a29-5a07d6e385ea"
      },
      "outputs": [],
      "source": [
        "# Transcribe the audio\n",
        "transcription = client.audio.transcriptions.create(\n",
        "    model=\"whisper-1\",\n",
        "    file=open(audio_path, \"rb\"),\n",
        ")\n",
        "## OPTIONAL: Uncomment the line below to print the transcription\n",
        "#print(\"Transcript: \", transcription.text + \"\\n\\n\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "    {\"role\": \"system\", \"content\":\"\"\"You are generating a transcript summary. Create a summary of the provided transcription. Respond in Markdown.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": [\n",
        "        {\"type\": \"text\", \"text\": f\"The audio transcription is: {transcription.text}\"}\n",
        "        ],\n",
        "    }\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8p2FANNXYV4"
      },
      "source": [
        "Audio + Visual Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeQ2pBqiXamg",
        "outputId": "ca90e837-5e22-48fe-8ac6-d15981bc0887"
      },
      "outputs": [],
      "source": [
        "## Generate a summary with visual and audio\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "    {\"role\": \"system\", \"content\":\"\"\"You are generating a video summary. Create a summary of the provided video and its transcript. Respond in Markdown\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": [\n",
        "        \"These are the frames from the video.\",\n",
        "        *map(lambda x: {\"type\": \"image_url\",\n",
        "                        \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, base64Frames),\n",
        "        {\"type\": \"text\", \"text\": f\"The audio transcription is: {transcription.text}\"}\n",
        "        ],\n",
        "    }\n",
        "],\n",
        "    temperature=0,\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBEK26xYX5DC"
      },
      "source": [
        "## Question and Answering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-RF7yl2KX67U"
      },
      "outputs": [],
      "source": [
        "QUESTION = \"Question: Why did Sam Altman have an example about raising windows and turning the radio on?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA5US6NYX810",
        "outputId": "a228e13e-4474-40b1-aa26-82a540a5ef56"
      },
      "outputs": [],
      "source": [
        "qa_visual_response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "    {\"role\": \"system\", \"content\": \"Use the video to answer the provided question. Respond in Markdown.\"},\n",
        "    {\"role\": \"user\", \"content\": [\n",
        "        \"These are the frames from the video.\",\n",
        "        *map(lambda x: {\"type\": \"image_url\", \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, base64Frames),\n",
        "        QUESTION\n",
        "        ],\n",
        "    }\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "print(\"Visual QA:\\n\" + qa_visual_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEfOdfIpX_-4",
        "outputId": "f80a38da-2d8f-4694-856d-2174f73e9add"
      },
      "outputs": [],
      "source": [
        "qa_audio_response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "    {\"role\": \"system\", \"content\":\"\"\"Use the transcription to answer the provided question. Respond in Markdown.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": f\"The audio transcription is: {transcription.text}. \\n\\n {QUESTION}\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "print(\"Audio QA:\\n\" + qa_audio_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYjiJkmNYCN-",
        "outputId": "2304a8fa-7418-43d5-9eeb-b1347a29ddc7"
      },
      "outputs": [],
      "source": [
        "qa_both_response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "    {\"role\": \"system\", \"content\":\"\"\"Use the video and transcription to answer the provided question.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": [\n",
        "        \"These are the frames from the video.\",\n",
        "        *map(lambda x: {\"type\": \"image_url\",\n",
        "                        \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, base64Frames),\n",
        "                        {\"type\": \"text\", \"text\": f\"The audio transcription is: {transcription.text}\"},\n",
        "        QUESTION\n",
        "        ],\n",
        "    }\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "print(\"Both QA:\\n\" + qa_both_response.choices[0].message.content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
